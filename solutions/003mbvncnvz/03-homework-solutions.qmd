---
title: "Section 3 Homework Solutions"
format: 
  html:
    self-contained: true
execute:
  echo: false
  warning: false
  fig-height: 3
---

__Exercise 1__. 

```{r}
library(tidyverse)
library(here)
survey_df <- read_csv(here("data_private/stat113_survey_f25.csv"))
ggplot(data = survey_df, aes(x = GPA)) +
  geom_histogram(bins = 19, colour = "darkorchid4", fill = "darkorchid1") +
  theme_minimal()
```

```{r}
summary_tab <- survey_df |>
  summarise(mean = mean(GPA, na.rm = TRUE),
            n = sum(!is.na(GPA)))

pander::pander(summary_tab)
```

a. $\hat{Y}$ = `r summary_tab$mean |> round(2)`,

where $\hat{Y}$ is predicted GPA points.

b. `r summary_tab$mean |> round(2)` points.

c. `r summary_tab$mean |> round(2)` points.

d. `r 2.5 - (summary_tab$mean |> round(2))` points.

e. `r 3.75 - (summary_tab$mean |> round(2))` points.

f. Our sample consists mostly of first and second year students. So, if GPA for juniors and seniors is systematically different for first and second year students, then our convenience sample is not representative of all SLU students.

<br>

__Exercise 2__.

```{r}
library(openintro)
library(tidyverse)
births_df <- openintro::births
ggplot(data = births_df, aes(x = m_age, y = weight)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()
```

```{r}
lm(weight ~ m_age, data = births_df) |> pander::pander()
```

```{r}
births_df |> slice(1:2) |>
  select(weight, m_age, smoke) |> pander::pander()
```

```{r}
mod <- lm(weight ~ m_age, data = births_df) 
mod_tidy <- mod |> broom::tidy()
```

a. $\hat{Y} =$ `r mod_tidy |> slice(1) |> pull(estimate) |> round(4)` + `r mod_tidy |> slice(2) |> pull(estimate) |> round(4)` X,

where $\hat{Y}$ is predicted weight, and $X$ is mother's age.

b. weak, slightly positive, and linear.

c. `r broom::augment(mod) |> slice(1) |> pull(.fitted) |> round(3)` pounds.

d. `r broom::augment(mod) |> slice(1) |> pull(.resid) |> round(3)` pounds.

e. The model is __over__-predicting the baby weight for this mother's baby, as the residual is negative (meaning that the fitted value is larger than the weight that was actually observed).

f. `r broom::augment(mod) |> slice(2) |> pull(.fitted) |> round(3)` pounds.

g. `r broom::augment(mod) |> slice(2) |> pull(.resid) |> round(3)` pounds.

<br>

__Exercise 3__.

```{r}
library(tidyverse); library(here)
golf_df <- read_csv(here("data/pga_data_final.csv"))
golf2018 <- golf_df |> filter(year == 2018) |>
  arrange(ranking)
pander::pander(golf2018 |>
  slice(1:3) |> select(-c(1, 2, 5, 6, 8, 9, 12, 13, 14,
                          15, 16, 17, 18, 19, 20, 21, 22)))
```

```{r}
ggplot(data = golf2018, aes(x = driving_accuracy, y = driving_distance)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(y = "driving distance (yards)", x = "percent fairways hit")
```

```{r}
lm(driving_distance ~ driving_accuracy, data = golf2018) |>
  pander::pander()
```

```{r}
mod_golf <- lm(driving_distance ~ driving_accuracy,
               data = golf2018)
mod_golf_tidy <- mod_golf |> broom::tidy()
```

a. $\hat{Y} =$ `r mod_golf_tidy |> slice(1) |> pull(estimate) |> round(2)` + `r mod_golf_tidy |> slice(2) |> pull(estimate) |> round(2)` X,

where $\hat{Y}$ is predicted distance in yards, and $X$ is the percent fairways hit.

b. `r broom::augment(mod_golf) |> slice(1) |> pull(.fitted) |> round(3)` yards.

c. `r broom::augment(mod_golf) |> slice(1) |> pull(.resid) |> round(3)` yards.

<br>

__Exercise 4__. Using the birth weight model from the earlier exercise (birth weight of the baby as the response (in pounds) and mother's age (in years) as the predictor, complete the following.

a. For a one year increase in age of the mother, we expect baby weight to increase by 0.0102 pounds, on average.

b. When age of the mother is 0 years, we expect baby weight to be 6.78 pounds, on average.

c. No: this is extrapolation. There are no mothers in the data set who are 0 years old (this would not make any sense).

d. The percentage of variability in baby weight that can be explained by a model with age of the mother is 0.179%.

<br>

__Exercise 5__.

a. For a one percent increase in fairways hit, we expect driving distance to decrease by 0.655 yards, on average.

b. When the percent of fairways hit is 0%, we expect the driving distance to be about 337 yards, on average.

c. No. There are no values even close to 0% fairways hit in the data set so this would be extrapolation.

d. The percentage of variability in driving distance that can be explained by a model with percent fairways hit is 15.59 %.

<br>

__Exercise 6__.

```{r}
ggplot(data = births_df, aes(x = smoke, y = weight)) +
  geom_boxplot(outlier.shape = 8, colour = "aquamarine4", fill = "aquamarine1") +
  theme_minimal()
```

```{r}
lm(weight ~ smoke, data = births_df) |> pander::pander()
```

```{r}
births_df |> slice(1:2) |>
  select(weight, m_age, smoke) |> pander::pander()
```

```{r}
mod_smoke <- lm(weight ~ smoke, data = births_df)
mod_smoke_tidy <- mod_smoke |> broom::tidy()
```

a. $\hat{Y} =$ `r mod_smoke_tidy |> slice(1) |> pull(estimate)` + `r mod_smoke_tidy |> slice(2) |> pull(estimate)` $smoke_{ind}$,

where $\hat{Y}$ is predicted weight, and $smoke_{ind}$ is equal to a $0$ if the mother was not a smoker and a $1$ if the mother was a smoker.

b. `r mod_smoke_tidy |> slice(1) |> pull(estimate) |> round(2)` pounds.

c. `r mod_smoke_tidy |> slice(1) |> pull(estimate) |> round(2) + mod_smoke_tidy |> slice(2) |> pull(estimate) |> round(2)` pounds.

d. `r broom::augment(mod_smoke) |> slice(1) |> pull(.resid)` pounds.

e. For mothers who do not smoke, we expect the average baby weight to be `r mod_smoke_tidy |> slice(1) |> pull(estimate)` pounds.

f. We expect the average baby weight for mothers who do smoke to be 0.4005 pounds less than the average baby weight for mothers who do not smoke.

<br>

__Exercise 7__.

```{r}
stroop_df <- read_csv("https://raw.githubusercontent.com/highamm/stat113/main/data_server/stroop.csv")
ggplot(data = stroop_df, aes(x = test, y = time)) +
  geom_boxplot(outlier.shape = 8, colour = "darkseagreen4", fill = "darkseagreen1") +
  theme_minimal()
```

```{r}
lm(time ~ test, data = stroop_df) |> pander::pander()
```

```{r}
mod_stroop <- lm(time ~ test, data = stroop_df)
mod_tidy_stroop <- mod_stroop |> broom::tidy()
```

a. $\hat{Y} =$ `r mod_tidy_stroop |> slice(1) |> pull(estimate) |> round(3)` + `r mod_tidy_stroop |> slice(2) |> pull(estimate) |> round(3)` $test_{ind}$,

where $\hat{Y}$ is the predicted time, and $test_{ind}$ is equal to a $0$ if the person was in the control test group and a $1$ if the person was in the stroop test group.

b. `r mod_tidy_stroop |> slice(1) |> pull(estimate) |> round(3)` seconds.

c. `r mod_tidy_stroop |> slice(1) |> pull(estimate) |> round(3) + mod_tidy_stroop |> slice(2) |> pull(estimate) |> round(3)` seconds.

d. We expect the time to complete the test for people in the control test group to be `r mod_tidy_stroop |> slice(1) |> pull(estimate) |> round(3)` seconds, on average.

```{r}
if (mod_tidy_stroop |> slice(2) |> pull(estimate) < 0) {
  more_or_less <- "less"
} else {
  more_or_less <- "more"
}
```

e. We expect time to complete the test for people in the stroop test group to be `r mod_tidy_stroop |> slice(2) |> pull(estimate) |> abs() |> round(3)` seconds `r more_or_less` than the the time to complete the test for people in the control test group, on average.

<br>

